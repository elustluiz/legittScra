name: LegittScra-Ultimate-Harvester

on:
  workflow_dispatch:
    inputs:
      search_engine:
        description: 'Engine'
        type: choice
        options: [google, bing, duckduckgo]
        default: 'google'
      search_depth:
        description: 'Pages'
        type: choice
        options: ['1', '3', '5']
        default: '3'
      custom_query:
        description: 'Manual Search String'
        required: false
        default: ''

jobs:
  build:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout Code
        uses: actions/checkout@v4
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'
      - name: Install dependencies
        run: pip install requests faker
      - name: Install OpenVPN
        run: sudo apt-get update && sudo apt-get install -y openvpn
      - name: Run Scraper
        env:
          PYTHONUNBUFFERED: "1" # Ensures you see logs on your ProBook in real-time
          ENGINE: ${{ github.event.inputs.search_engine }}
          DEPTH: ${{ github.event.inputs.search_depth }}
          UI_QUERY: ${{ github.event.inputs.custom_query }}
        run: python my_scraper.py
      - name: Commit and Push Data
        run: |
          git config --global user.name "GitHub Action"
          git config --global user.email "action@github.com"
          git add harvest_*.csv
          git commit -m "High-volume extract: $(date)" || echo "No new leads"
          git push
