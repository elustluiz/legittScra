name: LegittScra-Advanced-Interface

on:
  schedule:
    - cron: '0 */3 * * *'
  workflow_dispatch:
    inputs:
      search_engine:
        description: 'Choose Search Engine'
        type: choice
        options:
          - google
          - bing
          - duckduckgo
        default: 'google'
      custom_domains:
        description: 'Domains (e.g., talktalk.net, gmx.com)'
        required: true
        default: 'talktalk.net, gmx.com, tiscali.co.uk'
      custom_keywords:
        description: 'Search Keywords'
        required: true
        default: 'Treasurer OR CEO'

jobs:
  build:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout Code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'

      - name: Install dependencies
        run: pip install -r requirements.txt

      - name: Run Scraper
        env:
          # FORCES REAL-TIME LOGGING
          PYTHONUNBUFFERED: "1"
          ENGINE: ${{ github.event.inputs.search_engine }}
          UI_DOMAINS: ${{ github.event.inputs.custom_domains }}
          UI_KEYWORDS: ${{ github.event.inputs.custom_keywords }}
          TARGET_DOMAINS: ${{ secrets.TARGET_DOMAINS }}
          SEARCH_BASE_QUERY: ${{ secrets.SEARCH_BASE_QUERY }}
        run: python my_scraper.py

      - name: Commit and Push Data
        run: |
          git config --global user.name "GitHub Action"
          git config --global user.email "action@github.com"
          git add results.csv
          git commit -m "Scrape Results: $(date)" || echo "No changes"
          git push
